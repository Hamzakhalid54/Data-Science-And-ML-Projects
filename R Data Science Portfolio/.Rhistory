print(str(my.data))
# Assign column names from the matrix's dimnames attribute
colnames <- attr(my.data, "dimnames")[[2]]
# Create the new variables within my.data, which we will first convert to a data frame
my.data <- data.frame(my.data)
# Now set the names to the columns of the data frame
names(my.data) <- colnames
# Convert 'wind.speed' to km/h from m/s
my.data$WSB <- ifelse(as.numeric(my.data$wind.speed) * 3.6 > 25, "High", "Low")
# Categorize 'ambient.temp' according to specified ranges
my.data$TB <- ifelse(as.numeric(my.data$ambient.temp) > 30, "High",
ifelse(as.numeric(my.data$ambient.temp) >= 20, "Moderate", "Low"))
# Categorize 'irradiance' according to specified threshold
my.data$IrrB <- ifelse(as.numeric(my.data$irradiance) > 800, "High", "Low")
# Create the cross table for the new variables
cross_table <- table(my.data$WSB, my.data$TB, my.data$IrrB)
# Print the cross table
print(cross_table)
p_irrb_high <- (137 + 281 + 400 + 4 + 12) / (137 + 281 + 400 + 4 + 12 + 142 + 2576 + 1180 + 238 + 30)
p_irrb_high
p_irrb_low_given_tb_moderate_and_wsb_low <- (30) / (12 + 30)
p_irrb_low_given_tb_moderate_and_wsb_low
p_tb_high <- (142 + 137) / Total
p_irrb_low <- (142 + 2576 + 1180 + 238 + 30) / Total
independence_check <- p_tb_high * p_irrb_low == (142) / Total
# Total number of records
total_records <- 137 + 281 + 400 + 4 + 12 + 142 + 2576 + 1180 + 238 + 30
irrb_high_total <- 137 + 281 + 400 + 4 + 12
p_irrb_high <- irrb_high_total / total_records
p_irrb_high
wsb_low_total <- 4 + 12
p_tb_high_given_wsb_low <- 0 / wsb_low_total
p_tb_high_given_wsb_low
tb_moderate_and_wsb_low_total <- 12 + 30  # Total where TB is moderate and WSB is low
p_irrb_low_given_tb_moderate_and_wsb_low <- 30 / tb_moderate_and_wsb_low_total
p_irrb_low_given_tb_moderate_and_wsb_low
# Probability of TB being high
p_tb_high <- (142 + 137) / total_records
# Probability of IrrB being low
p_irrb_low <- (142 + 2576 + 1180 + 238 + 30) / total_records
# Check for independence
independence_check <- p_tb_high * p_irrb_low == 142 / total_records
p_tb_high
p_irrb_low
independence_check
mutual_exclusivity_check <- (281 == 0)
mutual_exclusivity_check
# R code snippet for plotting the prior and posterior distributions
library(ggplot2)
# Function to calculate the density of an inverse-gamma distribution
dinv_gamma <- function(x, shape, scale) {
return(scale^shape / gamma(shape) * x^(-shape - 1) * exp(-scale / x))
}
# Create a sequence of x values
x_values <- seq(0.01, 20, length.out = 1000)
# Calculate densities for prior and posterior
prior_density <- dinv_gamma(x_values, 0.5, 10)
posterior_density <- dinv_gamma(x_values, 3.5, 56)
# Convert to data frames for ggplot
prior_df <- data.frame(x_values, Density = prior_density)
posterior_df <- data.frame(x_values, Density = posterior_density)
# Plot the distributions
ggplot() +
geom_line(data = prior_df, aes(x = x_values, y = Density, color = "Prior"), size = 1) +
geom_line(data = posterior_df, aes(x = x_values, y = Density, color = "Posterior"), size = 1) +
labs(x = "Dwell Time", y = "Density", title = "Prior and Posterior Distributions") +
scale_color_manual(values = c("Prior" = "blue", "Posterior" = "red")) +
theme_minimal()
mu0 <- 150
sigma0 <- 20
sigma <- 10
xbar <- 160
# Function to calculate posterior mean and standard deviation
posterior_params <- function(n) {
mu_prime <- (mu0 / sigma0^2 + n * xbar / sigma^2) / (1 / sigma0^2 + n / sigma^2)
sigma_prime_squared <- 1 / (1 / sigma0^2 + n / sigma^2)
return(c(mu_prime, sqrt(sigma_prime_squared)))
}
# Calculations
n10 <- posterior_params(10)
n100 <- posterior_params(100)
print(paste("n=10: mu'=", n10[1], ", sigma'=", n10[2]))
# Calculations
n10 <- posterior_params(10)
n100 <- posterior_params(100)
print(paste("n=10: mu'=", n10[1], ", sigma'=", n10[2]))
print(paste("n=100: mu'=", n100[1], ", sigma'=", n100[2]))
#c
# Define the prior function piecewise
prior_function <- function(theta) {
ifelse(theta <= 150, 1/45000 * theta - 1/900,
ifelse(theta <= 200, -1/90000 * theta + 7/1800,
-1/30000 * theta - 1/120 + 251/120))
}
# Create a sequence of theta values
theta_values <- seq(50, 250, length.out = 1000)
prior_values <- Vectorize(prior_function)(theta_values)
# Normalize the prior (to ensure it integrates to 1 over its domain)
prior_values <- prior_values / sum(prior_values) * length(theta_values) / (max(theta_values) - min(theta_values))
# Plot the prior distribution
library(ggplot2)
ggplot(data.frame(theta = theta_values, Prior = prior_values), aes(x = theta, y = Prior)) +
geom_line(color = "blue") +
labs(title = "Prior Distribution of Height", x = expression(theta), y = "Density") +
theme_minimal()
# Hypothetical Likelihood (assuming it could be Gaussian with mean = 160, sd = 10)
likelihood_function <- function(theta) {
dnorm(theta, mean = 160, sd = 10)
}
likelihood_values <- likelihood_function(theta_values)
# Plot the likelihood distribution
ggplot(data.frame(theta = theta_values, Likelihood = likelihood_values), aes(x = theta, y = Likelihood)) +
geom_line(color = "red") +
labs(title = "Likelihood Distribution of Height", x = expression(theta), y = "Density") +
theme_minimal()
zz <- read.table("lettersdata.txt")
zz <- as.matrix(zz)
plot(zz, main="Scatterplot of the Data", xlab="Dimension 1", ylab="Dimension 2", col=4, pch=19)
k_value <- 5
# Perform k-means clustering
set.seed(42) # Ensure reproducibility
km_result <- kmeans(zz, centers=k_value)
# Show the results using a scatterplot
plot(zz, col=km_result$cluster, main="K-Means Clustering Results", xlab="Dimension 1", ylab="Dimension 2", pch=19)
points(km_result$centers, col=1:k_value, pch=8, cex=2)
# Assuming a tentative number of clusters (e.g., 5) based on visual examination
kmeans = KMeans(n_clusters=5, random_state=42)
zz['Cluster'] = kmeans.fit_predict(zz_matrix)
k_value <- 5
set.seed(42) # Ensure reproducibility
km_result <- kmeans(zz, centers=k_value)
plot(zz, col=km_result$cluster, main="K-Means Clustering Results", xlab="Dimension 1", ylab="Dimension 2", pch=19)
points(km_result$centers, col=1:k_value, pch=8, cex=2)
zz <- read.table("lettersdata.txt")
zz <- as.matrix(zz)
plot(zz, main="Scatterplot of the Data", xlab="Dimension 1", ylab="Dimension 2", col=4, pch=19)
k_value <- 5
set.seed(42)
km_result <- kmeans(zz, centers=k_value)
plot(zz, col=km_result$cluster, main="K-Means Clustering Results", xlab="Dimension 1", ylab="Dimension 2", pch=19)
points(km_result$centers, col=1:k_value, pch=8, cex=2)
k_values <- 2:20
totwss_values <- numeric(length(k_values))
for (i in seq_along(k_values)) {
set.seed(42) # Ensure reproducibility
km_result <- kmeans(zz, centers=k_values[i])
totwss_values[i] <- km_result$tot.withinss
}
plot(k_values, totwss_values, type="b", col="blue", main="TOTWSS vs Number of Clusters", xlab="Number of Clusters", ylab="TOTWSS", pch=19)
#2
# Load necessary library
library(kernlab)
# Perform spectral clustering
set.seed(42) # Ensure reproducibility
spcl <- specc(zz, centers=4) # Using 4 clusters as specified
# Convert clustering results to a numeric vector for plotting
spcl_clusters <- as.numeric(spcl)
# Plot the results of spectral clustering
plot(zz, col=spcl_clusters, main="Spectral Clustering Results", xlab="Dimension 1", ylab="Dimension 2", pch=19)
# Define the total cases and deaths for Florida and Arizona
florida_cases <- 7627999
florida_deaths <- 89075
arizona_cases <- 2486671
arizona_deaths <- 29852
# Define the priors for Florida and Arizona
florida_prior <- c(6000, 500000)
arizona_prior <- c(2700, 200000)
# Calculate the posterior distributions for Florida and Arizona
florida_posterior <- florida_prior + c(florida_deaths, florida_cases - florida_deaths)
arizona_posterior <- arizona_prior + c(arizona_deaths, arizona_cases - arizona_deaths)
# Calculate posterior medians and 95% credible intervals for Florida and Arizona
florida_median <- qbeta(0.5, florida_posterior[1], florida_posterior[2])
florida_credible_interval <- qbeta(c(0.025, 0.975), florida_posterior[1], florida_posterior[2])
arizona_median <- qbeta(0.5, arizona_posterior[1], arizona_posterior[2])
arizona_credible_interval <- qbeta(c(0.025, 0.975), arizona_posterior[1], arizona_posterior[2])
# Create a table-like structure for the results
results_table <- data.frame(
Location = c("Florida", "Arizona"),
Total_Cases = c(florida_cases, arizona_cases),
Total_Deaths = c(florida_deaths, arizona_deaths),
Posterior_Median = c(florida_median, arizona_median),
`95%_Credible_Interval_Lower` = c(florida_credible_interval[1], arizona_credible_interval[1]),
`95%_Credible_Interval_Upper` = c(florida_credible_interval[2], arizona_credible_interval[2])
)
# Print the results table
print(results_table)
# Plot the prior and posterior distributions for Florida
theta <- seq(0, 1, length.out = 1000)
prior_fl <- dbeta(theta, florida_prior[1], florida_prior[2])
posterior_fl <- dbeta(theta, florida_posterior[1], florida_posterior[2])
plot(theta, prior_fl, type = "l", col = "blue", ylim = c(0, max(posterior_fl)),
main = "Florida - Prior vs Posterior", xlab = "Fatality Rate", ylab = "Density")
lines(theta, posterior_fl, col = "red")
# Plot the prior and posterior distributions for Arizona
prior_az <- dbeta(theta, arizona_prior[1], arizona_prior[2])
posterior_az <- dbeta(theta, arizona_posterior[1], arizona_posterior[2])
plot(theta, prior_az, type = "l", col = "blue", ylim = c(0, max(posterior_az)),
main = "Arizona - Prior vs Posterior", xlab = "Fatality Rate", ylab = "Density")
lines(theta, posterior_az, col = "red")
# Load the data from the CSV file
the.fulldata <- read.csv("MelbAirportSolarData.csv", header = TRUE, sep = ",")
# Assuming you need to sample the data as per your original instructions
set.seed(123) # Setting a seed for reproducibility
sampled_indices <- sample(1:nrow(the.fulldata), 5000) # Adjust the number of rows if different
my.data <- the.fulldata[sampled_indices, ]
# Convert the data frame to a matrix (Ensure this is done if needed or skip if analysis on dataframe is preferable)
my.data <- as.matrix(my.data)
# Assuming 'Wind speed' is indeed the third column in the sampled data
wind_speed <- as.numeric(my.data[, 3]) # Ensure conversion to numeric in case of matrix type issues
# Generate a histogram for 'Wind speed'
hist(wind_speed, main = "Histogram of Wind Speed", xlab = "Wind Speed (m/s)", col = "lightblue", border = "blue")
# Generate a box plot for 'Wind speed'
boxplot(wind_speed, horizontal = TRUE, main = "Box Plot of Wind Speed", col = "lightgreen")
# Compute a five-number summary for 'Wind speed'
five_num_summary <- fivenum(wind_speed) # Tukey's five number summary
print(five_num_summary)
#1.3
# Assuming 'Temperature' is the second column and 'Humidity' is the fourth column in your dataset
temperature <- my.data[, 2] # Adjust if necessary
humidity <- my.data[, 4] # Adjust if necessary
# 1. Create a scatterplot for 'Temperature' and 'Humidity'
plot(temperature, humidity, xlab = "Temperature (°C)", ylab = "Humidity (%)", main = "Scatterplot of Temperature vs Humidity")
# 2. Fit a linear regression model to the variables
model <- lm(humidity ~ temperature)
# 3. Plot the regression line on the scatterplot
abline(model, col = "red")
humidity <- my.data[, 4] # Adjust if necessary
# 1. Create a scatterplot for 'Temperature' and 'Humidity'
plot(temperature, humidity, xlab = "Temperature (°C)", ylab = "Humidity (%)", main = "Scatterplot of Temperature vs Humidity")
# 2. Fit a linear regression model to the variables
model <- lm(humidity ~ temperature)
# 3. Plot the regression line on the scatterplot
abline(model, col = "red")
# 4. Write down the linear regression equation
# Intercept and slope (coefficients) of the linear model
intercept <- coef(model)[1]
slope <- coef(model)[2]
cat("The linear regression equation is: Humidity = ", intercept, " + ", slope, "*Temperature\n")
# 5. Compute the correlation coefficient
correlation_coefficient <- cor(temperature, humidity)
cat("Correlation coefficient: ", correlation_coefficient, "\n")
# 6. Compute the coefficient of Determination (R²)
r_squared <- summary(model)$r.squared
cat("Coefficient of Determination (R²): ", r_squared, "\n")
#1.4
# Check the structure of my.data
print(str(my.data))
# Assign column names from the matrix's dimnames attribute
colnames <- attr(my.data, "dimnames")[[2]]
# Create the new variables within my.data, which we will first convert to a data frame
my.data <- data.frame(my.data)
# Now set the names to the columns of the data frame
names(my.data) <- colnames
# Convert 'wind.speed' to km/h from m/s
my.data$WSB <- ifelse(as.numeric(my.data$wind.speed) * 3.6 > 25, "High", "Low")
# Categorize 'ambient.temp' according to specified ranges
my.data$TB <- ifelse(as.numeric(my.data$ambient.temp) > 30, "High",
ifelse(as.numeric(my.data$ambient.temp) >= 20, "Moderate", "Low"))
# Categorize 'irradiance' according to specified threshold
my.data$IrrB <- ifelse(as.numeric(my.data$irradiance) > 800, "High", "Low")
# Create the cross table for the new variables
cross_table <- table(my.data$WSB, my.data$TB, my.data$IrrB)
# Print the cross table
print(cross_table)
# Total number of records
total_records <- 137 + 281 + 400 + 4 + 12 + 142 + 2576 + 1180 + 238 + 30
irrb_high_total <- 137 + 281 + 400 + 4 + 12
p_irrb_high <- irrb_high_total / total_records
p_irrb_high
wsb_low_total <- 4 + 12
p_tb_high_given_wsb_low <- 0 / wsb_low_total
p_tb_high_given_wsb_low
tb_moderate_and_wsb_low_total <- 12 + 30  # Total where TB is moderate and WSB is low
p_irrb_low_given_tb_moderate_and_wsb_low <- 30 / tb_moderate_and_wsb_low_total
p_irrb_low_given_tb_moderate_and_wsb_low
# Probability of TB being high
p_tb_high <- (142 + 137) / total_records
p_tb_high
# Probability of IrrB being low
p_irrb_low <- (142 + 2576 + 1180 + 238 + 30) / total_records
p_irrb_low
# Check for independence
independence_check <- p_tb_high * p_irrb_low == 142 / total_records
independence_check
mutual_exclusivity_check <- (281 == 0)
mutual_exclusivity_check
#b
mu0 <- 150
sigma0 <- 20
sigma <- 10
xbar <- 160
# Function to calculate posterior mean and standard deviation
posterior_params <- function(n) {
mu_prime <- (mu0 / sigma0^2 + n * xbar / sigma^2) / (1 / sigma0^2 + n / sigma^2)
sigma_prime_squared <- 1 / (1 / sigma0^2 + n / sigma^2)
return(c(mu_prime, sqrt(sigma_prime_squared)))
}
# Calculations
n10 <- posterior_params(10)
n100 <- posterior_params(100)
print(paste("n=10: mu'=", n10[1], ", sigma'=", n10[2]))
print(paste("n=100: mu'=", n100[1], ", sigma'=", n100[2]))
#c
# Define the prior function piecewise
prior_function <- function(theta) {
ifelse(theta <= 150, 1/45000 * theta - 1/900,
ifelse(theta <= 200, -1/90000 * theta + 7/1800,
-1/30000 * theta - 1/120 + 251/120))
}
# Create a sequence of theta values
theta_values <- seq(50, 250, length.out = 1000)
prior_values <- Vectorize(prior_function)(theta_values)
# Normalize the prior (to ensure it integrates to 1 over its domain)
prior_values <- prior_values / sum(prior_values) * length(theta_values) / (max(theta_values) - min(theta_values))
# Plot the prior distribution
library(ggplot2)
ggplot(data.frame(theta = theta_values, Prior = prior_values), aes(x = theta, y = Prior)) +
geom_line(color = "blue") +
labs(title = "Prior Distribution of Height", x = expression(theta), y = "Density") +
theme_minimal()
# Hypothetical Likelihood (assuming it could be Gaussian with mean = 160, sd = 10)
likelihood_function <- function(theta) {
dnorm(theta, mean = 160, sd = 10)
}
likelihood_values <- likelihood_function(theta_values)
# Plot the likelihood distribution
ggplot(data.frame(theta = theta_values, Likelihood = likelihood_values), aes(x = theta, y = Likelihood)) +
geom_line(color = "red") +
labs(title = "Likelihood Distribution of Height", x = expression(theta), y = "Density") +
theme_minimal()
n1 <- posterior_params((1))
print(paste("n=1: mu'=", n1[1], ", sigma'=", n1[2]))
zz <- read.table("lettersdata.txt")
zz <- as.matrix(zz)
plot(zz, main="Scatterplot of the Data", xlab="Dimension 1", ylab="Dimension 2", col=4, pch=19)
k_value <- 5
set.seed(42)
km_result <- kmeans(zz, centers=k_value)
plot(zz, col=km_result$cluster, main="K-Means Clustering Results", xlab="Dimension 1", ylab="Dimension 2", pch=19)
k_values <- 2:20
totwss_values <- numeric(length(k_values))
for (i in seq_along(k_values)) {
set.seed(42) # Ensure reproducibility
km_result <- kmeans(zz, centers=k_values[i])
totwss_values[i] <- km_result$tot.withinss
}
plot(k_values, totwss_values, type="b", col="blue", main="TOTWSS vs Number of Clusters", xlab="Number of Clusters", ylab="TOTWSS", pch=19)
#2
# Load necessary library
library(kernlab)
# Perform spectral clustering
set.seed(42) # Ensure reproducibility
spcl <- specc(zz, centers=4) # Using 4 clusters as specified
# Convert clustering results to a numeric vector for plotting
spcl_clusters <- as.numeric(spcl)
# Plot the results of spectral clustering
plot(zz, col=spcl_clusters, main="Spectral Clustering Results", xlab="Dimension 1", ylab="Dimension 2", pch=19)
# R code snippet for plotting the prior and posterior distributions
library(ggplot2)
# Function to calculate the density of an inverse-gamma distribution
dinv_gamma <- function(x, shape, scale) {
return(scale^shape / gamma(shape) * x^(-shape - 1) * exp(-scale / x))
}
# Create a sequence of x values
x_values <- seq(0.01, 20, length.out = 1000)
# Calculate densities for prior and posterior
prior_density <- dinv_gamma(x_values, 0.5, 10)
posterior_density <- dinv_gamma(x_values, 3.5, 56)
# Convert to data frames for ggplot
prior_df <- data.frame(x_values, Density = prior_density)
posterior_df <- data.frame(x_values, Density = posterior_density)
# Plot the distributions
ggplot() +
geom_line(data = prior_df, aes(x = x_values, y = Density, color = "Prior"), size = 1) +
geom_line(data = posterior_df, aes(x = x_values, y = Density, color = "Posterior"), size = 1) +
labs(x = "Dwell Time", y = "Density", title = "Prior and Posterior Distributions") +
scale_color_manual(values = c("Prior" = "blue", "Posterior" = "red")) +
theme_minimal()
# Define the total cases and deaths for Florida and Arizona
florida_cases <- 7627999
florida_deaths <- 89075
arizona_cases <- 2486671
arizona_deaths <- 29852
# Define the priors for Florida and Arizona
florida_prior <- c(6000, 500000)
arizona_prior <- c(2700, 200000)
# Calculate the posterior distributions for Florida and Arizona
florida_posterior <- florida_prior + c(florida_deaths, florida_cases - florida_deaths)
arizona_posterior <- arizona_prior + c(arizona_deaths, arizona_cases - arizona_deaths)
# Calculate posterior medians and 95% credible intervals for Florida and Arizona
florida_median <- qbeta(0.5, florida_posterior[1], florida_posterior[2])
florida_credible_interval <- qbeta(c(0.025, 0.975), florida_posterior[1], florida_posterior[2])
arizona_median <- qbeta(0.5, arizona_posterior[1], arizona_posterior[2])
arizona_credible_interval <- qbeta(c(0.025, 0.975), arizona_posterior[1], arizona_posterior[2])
# Create a table-like structure for the results
results_table <- data.frame(
Location = c("Florida", "Arizona"),
Total_Cases = c(florida_cases, arizona_cases),
Total_Deaths = c(florida_deaths, arizona_deaths),
Posterior_Median = c(florida_median, arizona_median),
`95%_Credible_Interval_Lower` = c(florida_credible_interval[1], arizona_credible_interval[1]),
`95%_Credible_Interval_Upper` = c(florida_credible_interval[2], arizona_credible_interval[2])
)
# Print the results table
print(results_table)
# Plot the prior and posterior distributions for Florida
theta <- seq(0, 1, length.out = 1000)
prior_fl <- dbeta(theta, florida_prior[1], florida_prior[2])
posterior_fl <- dbeta(theta, florida_posterior[1], florida_posterior[2])
plot(theta, prior_fl, type = "l", col = "blue", ylim = c(0, max(posterior_fl)),
main = "Florida - Prior vs Posterior", xlab = "Fatality Rate", ylab = "Density")
lines(theta, posterior_fl, col = "red")
# Plot the prior and posterior distributions for Arizona
prior_az <- dbeta(theta, arizona_prior[1], arizona_prior[2])
posterior_az <- dbeta(theta, arizona_posterior[1], arizona_posterior[2])
plot(theta, prior_az, type = "l", col = "blue", ylim = c(0, max(posterior_az)),
main = "Arizona - Prior vs Posterior", xlab = "Fatality Rate", ylab = "Density")
lines(theta, posterior_az, col = "red")
# Load the data from the CSV file
the.fulldata <- read.csv("MelbAirportSolarData.csv", header = TRUE, sep = ",")
# Load the data from the CSV file
the.fulldata <- read.csv("MelbAirportSolarData.csv", header = TRUE, sep = ",")
# Assuming you need to sample the data as per your original instructions
set.seed(123) # Setting a seed for reproducibility
sampled_indices <- sample(1:nrow(the.fulldata), 5000) # Adjust the number of rows if different
my.data <- the.fulldata[sampled_indices, ]
# Convert the data frame to a matrix (Ensure this is done if needed or skip if analysis on dataframe is preferable)
my.data <- as.matrix(my.data)
# Assuming 'Wind speed' is indeed the third column in the sampled data
wind_speed <- as.numeric(my.data[, 3]) # Ensure conversion to numeric in case of matrix type issues
# Generate a histogram for 'Wind speed'
hist(wind_speed, main = "Histogram of Wind Speed", xlab = "Wind Speed (m/s)", col = "lightblue", border = "blue")
# Generate a box plot for 'Wind speed'
boxplot(wind_speed, horizontal = TRUE, main = "Box Plot of Wind Speed", col = "lightgreen")
# Compute a five-number summary for 'Wind speed'
five_num_summary <- fivenum(wind_speed) # Tukey's five number summary
print(five_num_summary)
# Alternatively, use summary for a traditional five-number summary plus mean
summary_windspeed <- summary(wind_speed)
print(summary_windspeed)
#1.3
# Assuming 'Temperature' is the second column and 'Humidity' is the fourth column in your dataset
temperature <- my.data[, 2] # Adjust if necessary
humidity <- my.data[, 4] # Adjust if necessary
# 1. Create a scatterplot for 'Temperature' and 'Humidity'
plot(temperature, humidity, xlab = "Temperature (°C)", ylab = "Humidity (%)", main = "Scatterplot of Temperature vs Humidity")
# 2. Fit a linear regression model to the variables
model <- lm(humidity ~ temperature)
# 3. Plot the regression line on the scatterplot
abline(model, col = "red")
# 4. Write down the linear regression equation
# Intercept and slope (coefficients) of the linear model
intercept <- coef(model)[1]
slope <- coef(model)[2]
cat("The linear regression equation is: Humidity = ", intercept, " + ", slope, "*Temperature\n")
# 5. Compute the correlation coefficient
correlation_coefficient <- cor(temperature, humidity)
cat("Correlation coefficient: ", correlation_coefficient, "\n")
# 6. Compute the coefficient of Determination (R²)
r_squared <- summary(model)$r.squared
cat("Coefficient of Determination (R²): ", r_squared, "\n")
#1.4
# Check the structure of my.data
print(str(my.data))
# Assign column names from the matrix's dimnames attribute
colnames <- attr(my.data, "dimnames")[[2]]
# Create the new variables within my.data, which we will first convert to a data frame
my.data <- data.frame(my.data)
# Now set the names to the columns of the data frame
names(my.data) <- colnames
# Convert 'wind.speed' to km/h from m/s
my.data$WSB <- ifelse(as.numeric(my.data$wind.speed) * 3.6 > 25, "High", "Low")
# Categorize 'ambient.temp' according to specified ranges
my.data$TB <- ifelse(as.numeric(my.data$ambient.temp) > 30, "High",
ifelse(as.numeric(my.data$ambient.temp) >= 20, "Moderate", "Low"))
# Categorize 'irradiance' according to specified threshold
my.data$IrrB <- ifelse(as.numeric(my.data$irradiance) > 800, "High", "Low")
# Create the cross table for the new variables
cross_table <- table(my.data$WSB, my.data$TB, my.data$IrrB)
# Print the cross table
print(cross_table)
# Total number of records
total_records <- 137 + 281 + 400 + 4 + 12 + 142 + 2576 + 1180 + 238 + 30
irrb_high_total <- 137 + 281 + 400 + 4 + 12
p_irrb_high <- irrb_high_total / total_records
p_irrb_high
wsb_low_total <- 4 + 12
p_tb_high_given_wsb_low <- 0 / wsb_low_total
p_tb_high_given_wsb_low
tb_moderate_and_wsb_low_total <- 12 + 30  # Total where TB is moderate and WSB is low
p_irrb_low_given_tb_moderate_and_wsb_low <- 30 / tb_moderate_and_wsb_low_total
# R code snippet for plotting the prior and posterior distributions
library(ggplot2)
# Function to calculate the density of an inverse-gamma distribution
dinv_gamma <- function(x, shape, scale) {
return(scale^shape / gamma(shape) * x^(-shape - 1) * exp(-scale / x))
}
# Create a sequence of x values
x_values <- seq(0.01, 20, length.out = 1000)
# Calculate densities for prior and posterior
prior_density <- dinv_gamma(x_values, 0.5, 10)
posterior_density <- dinv_gamma(x_values, 3.5, 56)
# Convert to data frames for ggplot
prior_df <- data.frame(x_values, Density = prior_density)
posterior_df <- data.frame(x_values, Density = posterior_density)
# Plot the distributions
ggplot() +
geom_line(data = prior_df, aes(x = x_values, y = Density, color = "Prior"), size = 1) +
geom_line(data = posterior_df, aes(x = x_values, y = Density, color = "Posterior"), size = 1) +
labs(x = "Dwell Time", y = "Density", title = "Prior and Posterior Distributions") +
scale_color_manual(values = c("Prior" = "blue", "Posterior" = "red")) +
theme_minimal()
